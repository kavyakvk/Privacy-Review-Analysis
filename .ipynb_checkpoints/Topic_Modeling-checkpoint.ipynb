{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapted from https://towardsdatascience.com/topic-modeling-with-nlp-on-amazon-reviews-an-application-of-latent-dirichlet-allocation-lda-ae42a4c8b369\n",
    "#https://blog.insightdatascience.com/topic-modeling-and-sentiment-analysis-to-pinpoint-the-perfect-doctor-6a8fdd4a3904\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_products = [\"NestOutdoorCam\",\"NestMini\",\"NestIndoorCam\",\n",
    "                   \"WyzeCamPan\",\"NanitPlus\",\"ArloPro\",\n",
    "                   \"RingStickUpCam\",\"RingSpotlightCam\",\"RingIndoorCam\",\"RingFloodlightCam\"]\n",
    "doorbell_products = [\"RingVideoDoorbell\",\"NestVideoDoorbell\"]\n",
    "voice_assistant_products = [\"GoogleHomeMini\",\"NestMini\",\n",
    "                            \"Homepod\",\n",
    "                            \"EchoFlex\",\"EchoDot\"]\n",
    "videocall_products = [\"EchoShow\",\"EchoStudio\",\n",
    "                     \"NestHubMax\",\"FacebookPortal\"]\n",
    "other_products = [\"NestWifi\",\"NestThermostat\"]\n",
    "\n",
    "privacy_keywords = [\"privacy\", \"permission\", \"surveillance\",\n",
    "                    \"advertisement\",\"ads\",\"confidential\",\n",
    "                    \"monitor\",\"intrusion\",\"spy\",\"confidential\"]\n",
    "\n",
    "security_keywords = [\"security\",\"protection\",\"safety\",\"safe\",\n",
    "                     \"threat\",\"targeted\",\"secure\"]\n",
    "\n",
    "creepy_keywords = [\"creepy\", \"scary\", \"unusual\",\"invasive\",\n",
    "                   \"uncomfortable\",\"violate\",\"aware\",\"unaware\"]\n",
    "\n",
    "data_keywords = [\"data\", \"collection\", \"tos\", \"third-party\",\n",
    "                 \"terms\", \"delete\",\"save\",\"policy\",\"agree\",\n",
    "                 \"agreement\",\"consent\",\"storage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>product</th>\n",
       "      <th>version</th>\n",
       "      <th>date</th>\n",
       "      <th>verified</th>\n",
       "      <th>rating</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>PS</th>\n",
       "      <th>privacy</th>\n",
       "      <th>security</th>\n",
       "      <th>creepy</th>\n",
       "      <th>data</th>\n",
       "      <th>camera</th>\n",
       "      <th>doorbell</th>\n",
       "      <th>voice</th>\n",
       "      <th>videocall</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMZ</td>\n",
       "      <td>NestOutdoorCam</td>\n",
       "      <td>N/A</td>\n",
       "      <td>20 Aug 2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Of course, now that Google has purchased Nest,...</td>\n",
       "      <td>Google overreach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMZ</td>\n",
       "      <td>NestOutdoorCam</td>\n",
       "      <td>N/A</td>\n",
       "      <td>01 Sep 2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Get a different brand. We have had this for 2 ...</td>\n",
       "      <td>Had for 2 Years: Terrible Long-Term Quality &amp; ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMZ</td>\n",
       "      <td>NestOutdoorCam</td>\n",
       "      <td>N/A</td>\n",
       "      <td>15 Feb 2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Purchased another camera for my home that was ...</td>\n",
       "      <td>AWFUL Customer support !!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMZ</td>\n",
       "      <td>NestOutdoorCam</td>\n",
       "      <td>N/A</td>\n",
       "      <td>28 Nov 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>This is probably my most regretted investment ...</td>\n",
       "      <td>I wanted to love this, But became Aware (pun i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMZ</td>\n",
       "      <td>NestOutdoorCam</td>\n",
       "      <td>N/A</td>\n",
       "      <td>02 Aug 2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I had 2 of the 4 cameras that I bought install...</td>\n",
       "      <td>Returned product- Here is why.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source         product version         date  verified  rating  \\\n",
       "0    AMZ  NestOutdoorCam     N/A  20 Aug 2019         1     1.0   \n",
       "1    AMZ  NestOutdoorCam     N/A  01 Sep 2019         1     1.0   \n",
       "2    AMZ  NestOutdoorCam     N/A  15 Feb 2020         1     1.0   \n",
       "3    AMZ  NestOutdoorCam     N/A  28 Nov 2017         1     2.0   \n",
       "4    AMZ  NestOutdoorCam     N/A  02 Aug 2020         1     1.0   \n",
       "\n",
       "                                             content  \\\n",
       "0  Of course, now that Google has purchased Nest,...   \n",
       "1  Get a different brand. We have had this for 2 ...   \n",
       "2  Purchased another camera for my home that was ...   \n",
       "3  This is probably my most regretted investment ...   \n",
       "4  I had 2 of the 4 cameras that I bought install...   \n",
       "\n",
       "                                               title  PS  privacy  security  \\\n",
       "0                                   Google overreach   0        0         0   \n",
       "1  Had for 2 Years: Terrible Long-Term Quality & ...   1        0         1   \n",
       "2                          AWFUL Customer support !!   0        0         0   \n",
       "3  I wanted to love this, But became Aware (pun i...   1        0         1   \n",
       "4                     Returned product- Here is why.   1        1         0   \n",
       "\n",
       "   creepy  data  camera  doorbell  voice  videocall  other  \n",
       "0       0     0       1         0      0          0      0  \n",
       "1       0     0       1         0      0          0      0  \n",
       "2       0     0       1         0      0          0      0  \n",
       "3       1     1       1         0      0          0      0  \n",
       "4       1     0       1         0      0          0      0  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"all_reviews.csv\",dtype={'version': 'string'})\n",
    "df.fillna(\"N/A\", inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125813, 18)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8584, 18)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_good_reviews= df.loc[(df.security == 1)]#[0:10000]\n",
    "df_good_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create document-term matrix\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "data_cv = cv.fit_transform(df_good_reviews.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8584, 13425)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stop = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_stop.index = df_good_reviews.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle it for later use\n",
    "#import pickle\n",
    "#pickle.dump(cv, open(\"cv_stop.pkl\", \"wb\"))\n",
    "#data_stop.to_pickle(\"dtm_stop.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000x</th>\n",
       "      <th>00273</th>\n",
       "      <th>00am</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>...</th>\n",
       "      <th>zomoda</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zwave</th>\n",
       "      <th>éasy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125788</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125794</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125796</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125799</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125803</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8584 rows × 13425 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00  000  000x  00273  00am  00pm  01  02  03  04  ...  zomoda  zone  \\\n",
       "1        0    0     0      0     0     0   0   0   0   0  ...       0     0   \n",
       "3        0    0     0      0     0     0   0   0   0   0  ...       0     0   \n",
       "5        0    0     0      0     0     0   0   0   0   0  ...       0     0   \n",
       "7        0    0     0      0     0     0   0   0   0   0  ...       0     0   \n",
       "8        0    0     0      0     0     0   0   0   0   0  ...       0     0   \n",
       "...     ..  ...   ...    ...   ...   ...  ..  ..  ..  ..  ...     ...   ...   \n",
       "125788   0    0     0      0     0     0   0   0   0   0  ...       0     0   \n",
       "125794   0    0     0      0     0     0   0   0   0   0  ...       0     0   \n",
       "125796   0    0     0      0     0     0   0   0   0   0  ...       0     0   \n",
       "125799   0    0     0      0     0     0   0   0   0   0  ...       0     0   \n",
       "125803   0    0     0      0     0     0   0   0   0   0  ...       0     0   \n",
       "\n",
       "        zones  zoo  zoom  zoomed  zooming  zooms  zwave  éasy  \n",
       "1           0    0     0       0        0      0      0     0  \n",
       "3           0    0     0       0        0      0      0     0  \n",
       "5           0    0     0       0        0      0      0     0  \n",
       "7           0    0     0       0        0      0      0     0  \n",
       "8           0    0     0       0        0      0      0     0  \n",
       "...       ...  ...   ...     ...      ...    ...    ...   ...  \n",
       "125788      0    0     0       0        0      0      0     0  \n",
       "125794      0    0     0       0        0      0      0     0  \n",
       "125796      0    0     0       0        0      0      0     0  \n",
       "125799      0    0     0       0        0      0      0     0  \n",
       "125803      0    0     0       0        0      0      0     0  \n",
       "\n",
       "[8584 rows x 13425 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in our document-term matrix\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "#data = pd.read_pickle('dtm_stop.pkl')\n",
    "data = data_stop\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules for LDA with gensim\n",
    "# Terminal / Anaconda Navigator: conda install -c conda-forge gensim\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>17</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>25</th>\n",
       "      <th>...</th>\n",
       "      <th>125760</th>\n",
       "      <th>125765</th>\n",
       "      <th>125769</th>\n",
       "      <th>125776</th>\n",
       "      <th>125784</th>\n",
       "      <th>125788</th>\n",
       "      <th>125794</th>\n",
       "      <th>125796</th>\n",
       "      <th>125799</th>\n",
       "      <th>125803</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000x</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00273</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00am</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8584 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1       3       5       7       8       17      21      22      23      \\\n",
       "00          0       0       0       0       0       0       0       0       0   \n",
       "000         0       0       0       0       0       0       0       0       0   \n",
       "000x        0       0       0       0       0       0       0       0       0   \n",
       "00273       0       0       0       0       0       0       0       0       0   \n",
       "00am        0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       25      ...  125760  125765  125769  125776  125784  125788  125794  \\\n",
       "00          0  ...       0       0       0       0       0       0       0   \n",
       "000         0  ...       0       0       0       0       0       0       0   \n",
       "000x        0  ...       0       0       0       0       0       0       0   \n",
       "00273       0  ...       0       0       0       0       0       0       0   \n",
       "00am        0  ...       0       0       0       0       0       0       0   \n",
       "\n",
       "       125796  125799  125803  \n",
       "00          0       0       0  \n",
       "000         0       0       0  \n",
       "000x        0       0       0  \n",
       "00273       0       0       0  \n",
       "00am        0       0       0  \n",
       "\n",
       "[5 rows x 8584 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One of the required inputs is a term-document matrix\n",
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to put the term-document matrix into a new gensim format, from df --> sparse matrix --> gensim corpus\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim also requires dictionary of the all terms and their respective location in the term-document matrix\n",
    "#cv = pickle.load(open(\"cv_stop.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.065*\"the\" + 0.034*\"to\" + 0.025*\"and\" + 0.025*\"it\" + 0.017*\"is\" + 0.014*\"of\" + 0.013*\"that\" + 0.011*\"my\" + 0.010*\"have\" + 0.010*\"you\"'),\n",
       " (1,\n",
       "  '0.076*\"we\" + 0.044*\"our\" + 0.034*\"and\" + 0.029*\"to\" + 0.028*\"the\" + 0.022*\"of\" + 0.019*\"in\" + 0.015*\"it\" + 0.015*\"for\" + 0.013*\"was\"'),\n",
       " (2,\n",
       "  '0.055*\"and\" + 0.046*\"the\" + 0.039*\"to\" + 0.035*\"security\" + 0.030*\"easy\" + 0.029*\"camera\" + 0.029*\"great\" + 0.028*\"is\" + 0.020*\"for\" + 0.018*\"very\"'),\n",
       " (3,\n",
       "  '0.045*\"the\" + 0.033*\"to\" + 0.027*\"and\" + 0.021*\"it\" + 0.018*\"you\" + 0.018*\"for\" + 0.016*\"is\" + 0.013*\"of\" + 0.012*\"in\" + 0.011*\"that\"'),\n",
       " (4,\n",
       "  '0.044*\"the\" + 0.038*\"my\" + 0.031*\"it\" + 0.031*\"to\" + 0.031*\"and\" + 0.025*\"is\" + 0.018*\"can\" + 0.016*\"on\" + 0.015*\"home\" + 0.015*\"you\"')]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term),\n",
    "# we need to specify two other parameters as well - the number of topics and the number of passes\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=5, passes=30)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/kavyakopparapu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/kavyakopparapu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger') \n",
    "import string\n",
    "from nltk import word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brand years things First t motion notification...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>investment time % subscription service AFTER p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>options security cameras Nest option camera pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nest cameras security Nest company Google way ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>product quality product Google Nest years Augu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125788</th>\n",
       "      <td>product security home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125794</th>\n",
       "      <td>camera work sense call trips home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125796</th>\n",
       "      <td>family secure night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125799</th>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125803</th>\n",
       "      <td>product home Best Buy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8584 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content\n",
       "1       brand years things First t motion notification...\n",
       "3       investment time % subscription service AFTER p...\n",
       "5       options security cameras Nest option camera pa...\n",
       "7       Nest cameras security Nest company Google way ...\n",
       "8       product quality product Google Nest years Augu...\n",
       "...                                                   ...\n",
       "125788                              product security home\n",
       "125794                  camera work sense call trips home\n",
       "125796                                family secure night\n",
       "125799                                            product\n",
       "125803                              product home Best Buy\n",
       "\n",
       "[8584 rows x 1 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nouns = pd.DataFrame(df_good_reviews.content.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new document-term matrix using only nouns\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Re-add the additional stop words since we are recreating the document-term matrix\n",
    "add_stop_words = ['like', 'im', 'know', 'just', 'dont', 'thats', 'right', 'people',\n",
    "                  'youre', 'got', 'gonna', 'time', 'think', 'yeah', 'said']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "\n",
    "# Recreate a document-term matrix with only nouns\n",
    "cvn = CountVectorizer(stop_words=stop_words)\n",
    "data_cvn = cvn.fit_transform(data_nouns.content)\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names())\n",
    "data_dtmn.index = data_nouns.index\n",
    "\n",
    "# Create the gensim corpus\n",
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.039*\"wifi\" + 0.021*\"installation\" + 0.016*\"house\" + 0.015*\"bit\" + 0.012*\"mount\" + 0.012*\"device\" + 0.012*\"fi\" + 0.012*\"wall\" + 0.011*\"wi\" + 0.011*\"signal\"'),\n",
       " (1,\n",
       "  '0.088*\"cameras\" + 0.071*\"camera\" + 0.043*\"security\" + 0.040*\"arlo\" + 0.025*\"video\" + 0.024*\"nest\" + 0.018*\"subscription\" + 0.015*\"storage\" + 0.015*\"quality\" + 0.014*\"home\"'),\n",
       " (2,\n",
       "  '0.229*\"motion\" + 0.055*\"detection\" + 0.039*\"camera\" + 0.026*\"sensor\" + 0.025*\"alerts\" + 0.022*\"sensitivity\" + 0.021*\"video\" + 0.020*\"driveway\" + 0.017*\"door\" + 0.017*\"zones\"'),\n",
       " (3,\n",
       "  '0.132*\"cam\" + 0.125*\"nest\" + 0.075*\"home\" + 0.051*\"secure\" + 0.040*\"cams\" + 0.037*\"thermostat\" + 0.033*\"security\" + 0.026*\"buy\" + 0.023*\"best\" + 0.014*\"products\"'),\n",
       " (4,\n",
       "  '0.079*\"alexa\" + 0.063*\"echo\" + 0.039*\"device\" + 0.034*\"devices\" + 0.033*\"amazon\" + 0.030*\"music\" + 0.028*\"security\" + 0.027*\"google\" + 0.025*\"screen\" + 0.020*\"sound\"'),\n",
       " (5,\n",
       "  '0.021*\"issues\" + 0.020*\"support\" + 0.019*\"wifi\" + 0.018*\"product\" + 0.018*\"issue\" + 0.017*\"service\" + 0.016*\"app\" + 0.016*\"customer\" + 0.015*\"device\" + 0.012*\"problem\"'),\n",
       " (6,\n",
       "  '0.116*\"light\" + 0.072*\"security\" + 0.065*\"ring\" + 0.063*\"lights\" + 0.063*\"camera\" + 0.062*\"floodlight\" + 0.042*\"flood\" + 0.028*\"cam\" + 0.017*\"app\" + 0.016*\"spotlight\"'),\n",
       " (7,\n",
       "  '0.150*\"night\" + 0.093*\"camera\" + 0.072*\"vision\" + 0.048*\"security\" + 0.037*\"picture\" + 0.032*\"yard\" + 0.032*\"backyard\" + 0.031*\"day\" + 0.029*\"view\" + 0.025*\"great\"'),\n",
       " (8,\n",
       "  '0.069*\"easy\" + 0.046*\"app\" + 0.031*\"pan\" + 0.024*\"install\" + 0.021*\"area\" + 0.019*\"ability\" + 0.013*\"quality\" + 0.013*\"super\" + 0.013*\"areas\" + 0.013*\"options\"'),\n",
       " (9,\n",
       "  '0.182*\"battery\" + 0.051*\"life\" + 0.043*\"batteries\" + 0.033*\"base\" + 0.024*\"station\" + 0.021*\"charge\" + 0.018*\"weeks\" + 0.018*\"wire\" + 0.017*\"months\" + 0.016*\"panel\"'),\n",
       " (10,\n",
       "  '0.160*\"home\" + 0.147*\"security\" + 0.065*\"product\" + 0.053*\"great\" + 0.037*\"house\" + 0.036*\"camera\" + 0.033*\"mind\" + 0.023*\"cameras\" + 0.021*\"peace\" + 0.019*\"addition\"'),\n",
       " (11,\n",
       "  '0.148*\"ring\" + 0.126*\"doorbell\" + 0.094*\"door\" + 0.046*\"security\" + 0.042*\"video\" + 0.025*\"home\" + 0.020*\"house\" + 0.017*\"product\" + 0.017*\"bell\" + 0.015*\"app\"'),\n",
       " (12,\n",
       "  '0.078*\"protection\" + 0.045*\"ring\" + 0.044*\"alarm\" + 0.043*\"plan\" + 0.020*\"device\" + 0.020*\"dog\" + 0.020*\"year\" + 0.019*\"adt\" + 0.013*\"month\" + 0.013*\"alarms\"'),\n",
       " (13,\n",
       "  '0.039*\"power\" + 0.025*\"cameras\" + 0.023*\"cable\" + 0.015*\"things\" + 0.014*\"house\" + 0.014*\"cord\" + 0.012*\"alarm\" + 0.012*\"unit\" + 0.011*\"usb\" + 0.010*\"generation\"'),\n",
       " (14,\n",
       "  '0.189*\"camera\" + 0.087*\"security\" + 0.063*\"quality\" + 0.033*\"app\" + 0.030*\"picture\" + 0.027*\"video\" + 0.023*\"wyze\" + 0.022*\"price\" + 0.019*\"phone\" + 0.018*\"cameras\"')]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try topics = 3\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=15, id2word=id2wordn, passes=30)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>different brand years many things wrong First ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regretted investment long time ignorant % usef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>many options outdoor security cameras Nest opt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nest cameras security Nest company ok Google w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>product quality product Google Nest few years ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125788</th>\n",
       "      <td>product helpful security home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125794</th>\n",
       "      <td>camera work good sense call long trips home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125796</th>\n",
       "      <td>family secure night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125799</th>\n",
       "      <td>Great product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125803</th>\n",
       "      <td>product secure home Best Buy best</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8584 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content\n",
       "1       different brand years many things wrong First ...\n",
       "3       regretted investment long time ignorant % usef...\n",
       "5       many options outdoor security cameras Nest opt...\n",
       "7       Nest cameras security Nest company ok Google w...\n",
       "8       product quality product Google Nest few years ...\n",
       "...                                                   ...\n",
       "125788                      product helpful security home\n",
       "125794        camera work good sense call long trips home\n",
       "125796                                family secure night\n",
       "125799                                      Great product\n",
       "125803                  product secure home Best Buy best\n",
       "\n",
       "[8584 rows x 1 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "def nouns_adj(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)\n",
    "\n",
    "data_nouns_adj = pd.DataFrame(df_good_reviews.content.apply(nouns_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new document-term matrix using only nouns and adjectives, also remove common words with max_df\n",
    "cvna = CountVectorizer(max_df=.8) #, max_df is used for removing data values that appear too frequently, also known as \"corpus-specific stop words\". \n",
    "# For example, max_df=.8 means \"It ignores terms that appear in more than 80% of the documents\". \n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.content)\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names())\n",
    "data_dtmna.index = data_nouns_adj.index\n",
    "\n",
    "# Create the gensim corpus\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.027*\"camera\" + 0.014*\"cameras\" + 0.012*\"security\" + 0.011*\"ring\" + 0.011*\"time\" + 0.010*\"video\" + 0.010*\"app\" + 0.009*\"motion\" + 0.009*\"nest\" + 0.009*\"doorbell\"'),\n",
       " (1,\n",
       "  '0.023*\"security\" + 0.022*\"home\" + 0.020*\"alexa\" + 0.018*\"echo\" + 0.014*\"nest\" + 0.011*\"show\" + 0.009*\"room\" + 0.009*\"devices\" + 0.009*\"smart\" + 0.009*\"device\"'),\n",
       " (2,\n",
       "  '0.051*\"security\" + 0.044*\"great\" + 0.042*\"camera\" + 0.032*\"easy\" + 0.026*\"home\" + 0.024*\"ring\" + 0.019*\"door\" + 0.016*\"motion\" + 0.015*\"system\" + 0.014*\"house\"')]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=3, id2word=id2wordna, passes=30)\n",
    "ldana.print_topics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
